{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Seblao/R-seaux-Neurones/blob/main/Building_a_VGG16_CNN_network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uYmYJ8c7zwTf"
      },
      "source": [
        "# Preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ueie00-eGAB1"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import os\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras import models, layers"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UoFTdFdDz5bH"
      },
      "source": [
        "# Tasks\n",
        "In this quest, you will be working on a classic CNN task of classifying cats and dogs images. You can access the training and testing sets [here](https://drive.google.com/drive/folders/19EL9VyYCVqxStG-O1jJtBQGa8JZpLDvO?usp=sharing) and get acquainted with the folder structure.\n",
        "\n",
        "Make sure to change your Colab runtime to GPU to ensure adequate performance.\n",
        "\n",
        "Specify 4 directories for cats and dogs images of training and testing sets respectively. You will be using them to build and train the network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HfWzrYG2GzjK"
      },
      "source": [
        "├── training_set/\n",
        "│   ├── cats/\n",
        "│   │   ├── cat001.jpg\n",
        "│   │   ├── cat002.jpg\n",
        "│   │   └── ...\n",
        "│   └── dogs/\n",
        "│       ├── dog001.jpg\n",
        "│       ├── dog002.jpg\n",
        "│       └── ...\n",
        "├── test_set/\n",
        "    ├── cats/\n",
        "    │   ├── cat101.jpg\n",
        "    │   ├── cat102.jpg\n",
        "    │   └── ...\n",
        "    └── dogs/\n",
        "        ├── dog101.jpg\n",
        "        ├── dog102.jpg\n",
        "        └── ..."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e2LfwrorE97e",
        "outputId": "4b0e8c77-fb93-4e17-d9e0-c010f24c81fd"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "root_path = '/content/drive/MyDrive'\n",
        "print(os.listdir(root_path))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "20Yr01YuJ4cO",
        "outputId": "4c0db256-1eae-46fb-a214-139b5e5f8acc"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['WildCodeSchool', 'Colab Notebooks', 'EBP', 'Simplon', 'ACEDM', 'Clinifutur', \"Fréquence d'utilisation des variables par processus de contrôle.xlsx\", 'EnqueteGlobale_17120224.ipynb', 'Attestation Jérémy PAROT.docx', '20250423_091344[1].jpg']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_path = os.path.join(root_path, 'WildCodeSchool')\n",
        "print(os.listdir(data_path))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8qdEtfYxKEcK",
        "outputId": "1c8f8569-ff99-4977-dee7-e51cb8328900"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Banquebdd.sql', 'Copie de Untitled1.ipynb', 'Challenge.Création.Business.Modèle.docx', 'Copie de Quête Introduction au Machine Learning - Régréssion linéaire simple, multiple et polynomiale.ipynb', 'Copie de Quete_Logistic_Regression_Titanic.ipynb', 'Copie de  1.3 ML - Train test split.ipynb', 'Copie de Copie de Quete Titanic re.ipynb', 'Copie de Standardize your data.ipynb', 'CNN – Utilisat° de mdèles pré-entraînés.ipynb', 'test_set', 'training_set']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = '/content/drive/MyDrive/WildCodeSchool/training_set'\n",
        "test_dir = '/content/drive/MyDrive/WildCodeSchool/test_set'"
      ],
      "metadata": {
        "id": "OKxXly53KSVF"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WA-BElFI1Dp0"
      },
      "source": [
        "Initiate `ImageDataGenerator` (check the [documentation](https://keras.io/api/preprocessing/image/)). Your image generator needs to convert the image from RGB into number arrays in order for the neural network to proces them (in other words, normalize the values using the `rescale` parameter)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qeamAdYNG2p7"
      },
      "source": [
        "# Préparat° des données avec ImageDataGenerator :\n",
        "# Générateur pr l'entraînemt (avec nrmalisat° des images 0-1) :\n",
        "train_datagen = ImageDataGenerator(rescale=1.0/255)\n",
        "\n",
        "# Générateur pr le test (égalemt nrmalisé) :\n",
        "test_datagen = ImageDataGenerator(rescale=1.0/255)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2lBwOKGX_1zs"
      },
      "source": [
        "Apply the `ImageDataGenerator` you defined above using `flow_from_directory` to convert both training and testing data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q5HdRYqyG4lL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e274af5b-3eac-4be1-a1ec-245057f6b7f4"
      },
      "source": [
        "# Chrgemt des images depuis les dossiers :\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(224, 224), # Taille d'entrée VGG16\n",
        "    batch_size=32,\n",
        "    class_mode='binary'  # binaire = chat ou chien\n",
        ")\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='binary'\n",
        ")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 8000 images belonging to 2 classes.\n",
            "Found 2000 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W2lefjC3Ag31"
      },
      "source": [
        "Build a convolutional neural network based on the [VGG16](https://neurohive.io/en/popular-networks/vgg16/) architecture."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_uMxeBohrhE-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6aa2e698-feb1-4b73-d53d-d79941ed0419"
      },
      "source": [
        "# Cstruct° du modèle CNN basé sur VGG16 :\n",
        "# Chrge VGG16 sans la partie classificat° (top) :\n",
        "conv_base = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# Geler les couches de VGG16 pr ne pas les réentraîner :\n",
        "conv_base.trainable = False\n",
        "\n",
        "# Ajte 1 tête personnalisée :\n",
        "model = models.Sequential()\n",
        "model.add(conv_base)\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(256, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))  # Binaire (car chat ou chien)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m58889256/58889256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yfKfaaQ9E6C_"
      },
      "source": [
        "Compile it using the optimizer and error metrics of your choice."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yKQmcixNygwu"
      },
      "source": [
        "# Cpilat° du mdèle :\n",
        "model.compile(\n",
        "    loss='binary_crossentropy',\n",
        "    optimizer='adam',\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z3nYV_b8BdNs"
      },
      "source": [
        "Fit the model using `fit_generator`. This time, feel free to define the parameters according to your understanding and experiment with them to find a better solution. Be patient though, the training will take a while."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l3hVpkBMyovN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "3cd84256-f831-4f77-8e32-73b0fdf41b21"
      },
      "source": [
        "# Entraînemt du mdèle :\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
        "    epochs=10,\n",
        "    validation_data=test_generator,\n",
        "    validation_steps=test_generator.samples // test_generator.batch_size\n",
        ")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'model' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-77d852cd5cb5>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Entraînemt du mdèle :\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m history = model.fit(\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mtrain_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bfNnYxh7Bw6c"
      },
      "source": [
        "Plot the model accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oilYhnVmyrpK"
      },
      "source": [
        "# Visualisat° de la précis° :\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(epochs, acc, 'bo-', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'ro-', label='Validation acc')\n",
        "plt.title('Accuracy du modèle')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}